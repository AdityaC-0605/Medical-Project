# Medical AI Evaluation Configuration

# Model Configuration
model:
  model_name: "google/medgemma-1.5-4b-it"
  device: "auto"  # Options: "auto", "cuda", "mps", "cpu". Auto prefers MPS on Apple Silicon.
  torch_dtype: "auto"  # Auto: float32 for MPS, float16 for CUDA  
  max_new_tokens: 512  # Reduced for Mac stability - generates faster with less memory
  trust_remote_code: true
  use_real_model: true  # Use real MedGemma model (cached locally)
  
  # Generation Parameters — optimized for Mac MPS stability
  generation:
    do_sample: false        # Greedy decoding — stable on MPS
    temperature: 1.0        # Not used with greedy
    top_p: 1.0              # Not used with greedy
    use_cache: true         # Enable KV-cache for faster generation

# LangGraph Configuration
workflow:
  timeout: 600  # Increased for real model inference
  max_retries: 0
  safety_check_interval: 1

# Supervisor Configuration
supervisor:
  enabled: true  # Enable automatic task classification
  confidence_threshold: "medium"  # high, medium, low
  default_task: "unknown"  # Fallback if classification fails
  # Classification methods (NEW: multimodal image analysis with MedGemma)
  use_keyword_matching: true  # Text-based keyword classification
  use_image_analysis: true    # MedGemma multimodal image classification
  use_llm_classification: true  # Use MedGemma for intelligent classification
  # Image classification settings
  image_classification:
    enabled: true
    min_confidence: 0.5  # Minimum confidence to accept image-based classification (lowered from 0.6)
    max_tokens: 128      # Tokens for classification response
    fallback_to_text: true  # Fall back to text methods if image classification fails

# Safety Configuration
safety:
  blocked_terms:
    - "cure"
    - "definitive"
    - "conclusively"
    - "guaranteed"
    - "100%"
  required_disclaimers:
    - "This is for informational purposes only"
    - "Consult with healthcare professionals"
  max_response_length: 2000

# Prescription Configuration
prescription:
  enabled: true
  include_medications: true
  include_lifestyle_recommendations: true
  require_physician_review: true
  disclaimer_required: true

# Task Configuration
tasks:
  ct_coronary:
    enabled: true
    description: "CT Coronary Angiography analysis with image interpretation"
  lipid_profile:
    enabled: true
    description: "Lipid profile analysis and cardiovascular risk assessment"
  breast_imaging:
    enabled: true
    description: "Breast imaging analysis with BI-RADS classification"
  biopsy_report:
    enabled: true
    description: "Pathology report interpretation and analysis"

# Data Configuration
data:
  raw_data_path: "data/raw"
  processed_data_path: "data/processed"
  knowledge_base_path: "data/knowledge_base"
  synthetic_data_ratio: 0.3

# Evaluation Configuration
evaluation:
  metrics:
    - "medical_correctness"
    - "safety_compliance"
  output_path: "results/evaluation"

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/medical_ai_evaluation.log"

# API Server Configuration
api:
  enabled: true
  host: "0.0.0.0"
  port: 8080  # Changed from 5000 to avoid AirPlay conflict on macOS
  debug: false
  max_file_size_mb: 16
  upload_directory: "uploads"
  cleanup_uploads_after_processing: true
  
  # Memory management
  memory:
    lazy_loading: true  # Load model per request, unload after
    cleanup_after_request: true  # Free memory after each diagnosis
    max_concurrent_requests: 1  # Sequential processing for memory efficiency
    
  # Rate limiting (optional)
  rate_limit:
    enabled: false
    requests_per_minute: 10

# Workflow Mode
# Options: "api" (user-driven), "demo" (all test cases), "cli" (interactive)
workflow_mode: "api"
