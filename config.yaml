# Medical AI Evaluation Configuration - macOS Optimized

# Model Configuration
model:
  model_name: "google/medgemma-1.5-4b-it"
  device: "auto"  # Options: "auto", "cuda", "mps", "cpu". Auto prefers MPS on Apple Silicon.
  torch_dtype: "auto"  # Auto: float32 for MPS, float16 for CUDA  
  max_new_tokens: 400  # Reduced for 20% faster generation while maintaining quality
  trust_remote_code: true
  use_real_model: true  # Use real MedGemma model (cached locally)
  
  # Generation Parameters ‚Äî optimized for Mac MPS stability
  generation:
    do_sample: false        # Greedy decoding ‚Äî stable on MPS
    num_beams: 1            # No beam search for MPS stability
    temperature: 0.7        # Used only if do_sample: true
    top_p: 0.9              # Used only if do_sample: true
    use_cache: true         # Enable KV-cache for faster generation
    pad_token_id: null      # Will be set from tokenizer
    eos_token_id: null      # Will be set from tokenizer
  
  # Image Processing Configuration (CRITICAL for multimodal)
  image_processing:
    enabled: true                      # Enable image + text processing
    image_token: "<<start_of_image>>"  # Gemma3 processor expects this token
    max_image_size: 384                # Smaller images for faster processing
    require_token_in_prompt: true      # CRITICAL: Ensures image token is added


# LangGraph Configuration
workflow:
  timeout: 420  # Reduced to 7 minutes with optimizations
  max_retries: 0
  safety_check_interval: 1
  preload_model: true  # Preload model at startup for better performance


# Supervisor Configuration
supervisor:
  enabled: true  # Enable automatic task classification
  confidence_threshold: "medium"  # high, medium, low
  default_task: "unknown"  # Fallback if classification fails
  
  # Classification methods (Priority order: image > filename > text > LLM)
  use_keyword_matching: true  # Text-based keyword classification
  use_image_analysis: true    # MedGemma multimodal image classification (PRIORITY)
  use_filename_analysis: true # Filename-based classification
  use_llm_classification: true  # Use MedGemma for intelligent classification
  
  # Image classification settings (NEW: Fixed configuration)
  image_classification:
    enabled: true
    priority: 0             # Highest priority (0 = first)
    min_confidence: 0.5     # Minimum confidence to accept (50%)
    max_tokens: 20          # Tokens for classification response (reduced for speed)
    do_sample: false        # Greedy decoding for faster, deterministic classification
    fallback_to_text: true  # Fall back to text methods if fails
    use_text_context: true  # Use accompanying text for better classification
  
  # Filename classification settings
  filename_classification:
    enabled: true
    priority: 1             # Second priority
    markers:
      ct_coronary: ["ct", "coronary", "cardiac", "ccta", "angiogram"]
      breast_imaging: ["mammogram", "mammography", "breast", "birads"]
      chest_xray: ["xray", "x-ray", "chest"]
  
  # Text classification settings
  text_classification:
    enabled: true
    priority: 2             # Third priority
    min_text_length: 10     # Minimum text length to attempt classification


# Safety Configuration
safety:
  blocked_terms:
    - "cure"
    - "definitive"
    - "conclusively"
    - "guaranteed"
    - "100%"
  required_disclaimers:
    - "This is for informational purposes only"
    - "Consult with healthcare professionals"
  max_response_length: 2000


# Prescription Configuration
prescription:
  enabled: true
  include_medications: true
  include_dosages: true
  include_lifestyle_recommendations: true
  include_follow_up: true
  require_physician_review: true
  disclaimer_required: true


# Task Configuration
tasks:
  ct_coronary:
    enabled: true
    description: "CT Coronary Angiography analysis with image interpretation"
    supports_images: true
    supports_text: true
  lipid_profile:
    enabled: true
    description: "Lipid profile analysis and cardiovascular risk assessment"
    supports_images: false
    supports_text: true
  breast_imaging:
    enabled: true
    description: "Breast imaging analysis with BI-RADS classification"
    supports_images: true
    supports_text: true
  biopsy_report:
    enabled: true
    description: "Pathology report interpretation and analysis"
    supports_images: false
    supports_text: true


# Data Configuration
data:
  raw_data_path: "data/raw"
  processed_data_path: "data/processed"
  knowledge_base_path: "data/knowledge_base"
  synthetic_data_ratio: 0.3


# Evaluation Configuration
evaluation:
  metrics:
    - "medical_correctness"
    - "safety_compliance"
    - "image_analysis_accuracy"
    - "diagnosis_quality"
  output_path: "results/evaluation"


# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/medical_ai_evaluation.log"
  console_output: true


# API Server Configuration
api:
  enabled: true
  host: "0.0.0.0"
  port: 8080  # Changed from 5000 to avoid AirPlay conflict on macOS
  debug: false
  max_file_size_mb: 16
  upload_directory: "uploads"
  cleanup_uploads_after_processing: false  # Keep for debugging
  
  # Supported file types
  supported_image_formats:
    - ".jpg"
    - ".jpeg"
    - ".png"
    - ".gif"
    - ".bmp"
    - ".tiff"
    - ".dcm"
  
  # Memory management (macOS optimized)
  memory:
    lazy_loading: false  # Preload model for better performance
    cleanup_after_request: true  # Clean up MPS cache after each request
    max_concurrent_requests: 1  # Sequential processing for memory efficiency
    force_gc_after_request: true  # Force garbage collection
    clear_mps_cache: true  # Clear MPS cache on macOS
    
  # Rate limiting (optional)
  rate_limit:
    enabled: false
    requests_per_minute: 10


# Streamlit Configuration
streamlit:
  enabled: true
  port: 8501
  title: "Medical AI Diagnosis System"
  page_icon: "üè•"
  layout: "wide"
  initial_sidebar_state: "expanded"


# Workflow Mode
# Options: "api" (user-driven), "demo" (all test cases), "cli" (interactive), "streamlit" (web UI)
workflow_mode: "streamlit"


# macOS Specific Optimizations
macos:
  use_mps: true  # Use Metal Performance Shaders on Apple Silicon
  mps_high_watermark_ratio: "0.0"  # Aggressive memory cleanup
  enable_mps_fallback: true  # Fallback to CPU for unsupported ops
  tokenizers_parallelism: false  # Disable for MPS stability
  omp_num_threads: 1  # Single thread for OpenMP
  malloc_arena_max: 2  # Limit memory arenas


# Debugging Configuration
debug:
  enabled: false
  save_intermediate_outputs: false
  log_model_outputs: true
  log_prompts: true
  verbose_logging: false


# Feature Flags
features:
  multimodal_analysis: true  # Enable image + text analysis
  structured_output: true    # Enable structured clinical assessments
  automatic_classification: true  # Enable supervisor auto-classification
  image_classification: true  # Enable MedGemma image classification
  fallback_responses: true   # Enable fallback when model fails
